{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eyFE2RDJsbSC"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4MvyNhIXfO4G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NFPDHlGQgJlM",
    "outputId": "0b52ff44-4081-4fb7-c8b1-dca72f60c80d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bot' 'clothes' 'plastic' 'steel']\n",
      "[[ 3.          1.54908948  2.39967822 ... 55.33333333 54.\n",
      "  58.        ]\n",
      " [ 3.          1.54908948  2.39967822 ... 55.33333333 54.\n",
      "  58.        ]\n",
      " [ 3.          1.54908948  2.39967822 ... 55.33333333 54.\n",
      "  58.        ]\n",
      " ...\n",
      " [ 5.          1.18798493  1.4113082  ... 58.4        53.\n",
      "  62.        ]\n",
      " [ 5.          1.18798493  1.4113082  ... 58.         53.\n",
      "  62.        ]\n",
      " [ 4.          1.31552158  1.73059701 ... 57.75       53.\n",
      "  63.        ]]\n",
      "[[ 6.          1.38134854  1.90812379 ... 59.         53.\n",
      "  66.        ]\n",
      " [ 7.          1.45780205  2.12518682 ... 58.71428571 53.\n",
      "  66.        ]\n",
      " [ 7.          1.45780272  2.12518877 ... 58.71428571 53.\n",
      "  66.        ]\n",
      " ...\n",
      " [ 8.          1.42236846  2.02313204 ... 58.375      53.\n",
      "  66.        ]\n",
      " [ 8.          1.26366319  1.59684467 ... 58.375      53.\n",
      "  66.        ]\n",
      " [ 7.          1.35292182  1.83039746 ... 59.         53.\n",
      "  67.        ]]\n",
      "[[ 5.          1.20000702  1.44001685 ... 59.         52.\n",
      "  70.        ]\n",
      " [ 6.          1.55876394  2.42974502 ... 57.66666667 51.\n",
      "  70.        ]\n",
      " [ 7.          1.44829581  2.09756075 ... 56.         45.\n",
      "  70.        ]\n",
      " ...\n",
      " [ 8.          0.98390243  0.96806399 ... 58.75       53.\n",
      "  69.        ]\n",
      " [ 6.          1.10935943  1.23067834 ... 59.83333333 53.\n",
      "  68.        ]\n",
      " [11.          1.14937861  1.32107119 ... 59.45454545 53.\n",
      "  69.        ]]\n",
      "[[ 6.          1.29951926  1.6887503  ... 60.66666667 54.\n",
      "  66.        ]\n",
      " [ 5.          1.22829922  1.50871898 ... 60.4        54.\n",
      "  66.        ]\n",
      " [ 5.          1.22830661  1.50873713 ... 60.4        54.\n",
      "  66.        ]\n",
      " ...\n",
      " [ 4.          1.31500734  1.72924429 ... 54.5        51.\n",
      "  60.        ]\n",
      " [ 5.          1.19938441  1.43852295 ... 52.         43.\n",
      "  60.        ]\n",
      " [ 4.          1.29803502  1.68489492 ... 55.25       51.\n",
      "  62.        ]]\n",
      "4092\n",
      "['bot' 'clothes' 'plastic' 'steel']\n",
      "[[ 5.          1.44443725  2.08639896 ... 58.2        53.\n",
      "  63.        ]\n",
      " [ 5.          1.4444805   2.08652391 ... 58.         53.\n",
      "  63.        ]\n",
      " [ 5.          1.4444805   2.08652391 ... 58.         53.\n",
      "  63.        ]\n",
      " ...\n",
      " [ 3.          1.52303744  2.31964306 ... 56.         53.\n",
      "  61.        ]\n",
      " [ 4.          1.34223883  1.80160509 ... 57.         53.\n",
      "  61.        ]\n",
      " [ 4.          1.34223883  1.80160509 ... 56.         52.\n",
      "  60.        ]]\n",
      "[[ 5.          0.74018628  0.54787573 ... 58.6        53.\n",
      "  71.        ]\n",
      " [ 4.          0.7602968   0.57805123 ... 58.         53.\n",
      "  71.        ]\n",
      " [ 4.          0.7602968   0.57805123 ... 58.         53.\n",
      "  71.        ]\n",
      " ...\n",
      " [ 6.          1.37237566  1.88341496 ... 59.         54.\n",
      "  64.        ]\n",
      " [ 6.          1.37238794  1.88344865 ... 58.33333333 54.\n",
      "  63.        ]\n",
      " [ 8.          1.21110314  1.46677082 ... 57.5        53.\n",
      "  63.        ]]\n",
      "[[ 8.          1.19719958  1.43328684 ... 58.375      51.\n",
      "  71.        ]\n",
      " [ 8.          1.19720254  1.43329393 ... 58.5        51.\n",
      "  70.        ]\n",
      " [ 8.          1.19719958  1.43328684 ... 58.5        51.\n",
      "  71.        ]\n",
      " ...\n",
      " [ 9.          1.27787244  1.63295798 ... 57.33333333 51.\n",
      "  70.        ]\n",
      " [ 6.          1.10011718  1.21025782 ... 58.         52.\n",
      "  71.        ]\n",
      " [ 6.          1.10056174  1.21123614 ... 58.66666667 52.\n",
      "  71.        ]]\n",
      "[[ 6.          1.44786619  2.0963165  ... 57.83333333 52.\n",
      "  63.        ]\n",
      " [ 5.          1.58246981  2.50421069 ... 56.6        51.\n",
      "  60.        ]\n",
      " [ 7.          1.34056406  1.79711199 ... 58.57142857 51.\n",
      "  64.        ]\n",
      " ...\n",
      " [ 6.          1.29097204  1.6666088  ... 58.66666667 53.\n",
      "  66.        ]\n",
      " [ 4.          1.32241873  1.7487913  ... 57.         53.\n",
      "  61.        ]\n",
      " [ 4.          1.32243316  1.74882947 ... 57.75       54.\n",
      "  61.        ]]\n",
      "3583\n",
      "['bot' 'clothes' 'plastic' 'steel']\n",
      "[[ 6.          1.59309762  2.53796001 ... 53.33333333 49.\n",
      "  59.        ]\n",
      " [ 6.          1.59309168  2.53794111 ... 53.         49.\n",
      "  58.        ]\n",
      " [ 6.          1.59307251  2.53788003 ... 53.         49.\n",
      "  59.        ]\n",
      " ...\n",
      " [ 5.          1.73447353  3.00839842 ... 52.8        49.\n",
      "  61.        ]\n",
      " [ 5.          1.73449707  3.00848009 ... 53.         49.\n",
      "  61.        ]\n",
      " [ 5.          1.73451911  3.00855653 ... 52.6        49.\n",
      "  59.        ]]\n",
      "[[ 7.          1.3353968   1.78328461 ... 51.28571429 45.\n",
      "  60.        ]\n",
      " [ 7.          1.33536699  1.78320501 ... 50.85714286 45.\n",
      "  59.        ]\n",
      " [ 7.          1.33534379  1.78314304 ... 50.85714286 45.\n",
      "  59.        ]\n",
      " ...\n",
      " [ 5.          1.85420833  3.43808854 ... 52.8        46.\n",
      "  59.        ]\n",
      " [ 5.          1.84617478  3.40836133 ... 53.         47.\n",
      "  59.        ]\n",
      " [ 6.          1.70184441  2.8962744  ... 53.33333333 47.\n",
      "  60.        ]]\n",
      "[[ 6.          1.40202477  1.96567345 ... 52.33333333 45.\n",
      "  60.        ]\n",
      " [ 5.          1.50197287  2.25592249 ... 52.         45.\n",
      "  59.        ]\n",
      " [ 5.          1.50197287  2.25592249 ... 52.6        46.\n",
      "  60.        ]\n",
      " ...\n",
      " [ 5.          1.69145025  2.86100395 ... 53.6        47.\n",
      "  61.        ]\n",
      " [ 5.          1.65985175  2.75510784 ... 54.6        47.\n",
      "  61.        ]\n",
      " [ 4.          1.84920887  3.41957346 ... 53.25       47.\n",
      "  60.        ]]\n",
      "[[ 6.          1.91679557  3.67410525 ... 51.33333333 45.\n",
      "  60.        ]\n",
      " [ 5.          1.89309855  3.58382213 ... 50.4        46.\n",
      "  53.        ]\n",
      " [ 5.          2.01578845  4.06340309 ... 51.8        46.\n",
      "  60.        ]\n",
      " ...\n",
      " [ 3.          1.851353    3.42750794 ... 48.66666667 46.\n",
      "  52.        ]\n",
      " [ 3.          1.851353    3.42750794 ... 48.66666667 46.\n",
      "  52.        ]\n",
      " [ 3.          1.851353    3.42750794 ... 47.33333333 44.\n",
      "  52.        ]]\n",
      "3570\n",
      "4092\n",
      "3583\n",
      "3570\n",
      "['bot' 'clothes' 'plastic' 'steel']\n",
      "[[ 6.          1.30390869  1.70017787 ... 61.33333333 54.\n",
      "  74.        ]\n",
      " [ 6.          1.30390869  1.70017787 ... 61.33333333 54.\n",
      "  74.        ]\n",
      " [ 6.          1.30392244  1.70021374 ... 61.33333333 54.\n",
      "  74.        ]\n",
      " ...\n",
      " [ 5.          1.1566181   1.33776543 ... 62.2        54.\n",
      "  72.        ]\n",
      " [ 5.          1.15658793  1.33769563 ... 62.6        54.\n",
      "  72.        ]\n",
      " [ 5.          1.1566181   1.33776543 ... 62.4        54.\n",
      "  72.        ]]\n",
      "[[ 5.          1.46356106  2.14201098 ... 57.8        54.\n",
      "  62.        ]\n",
      " [ 5.          1.46355868  2.142004   ... 57.8        54.\n",
      "  62.        ]\n",
      " [ 5.          1.46357108  2.1420403  ... 57.8        54.\n",
      "  62.        ]\n",
      " ...\n",
      " [ 5.          1.44715496  2.09425749 ... 57.8        53.\n",
      "  63.        ]\n",
      " [ 4.          1.60784753  2.58517368 ... 57.25       53.\n",
      "  63.        ]\n",
      " [ 5.          1.16106552  1.34807315 ... 56.8        52.\n",
      "  63.        ]]\n",
      "[[ 6.          1.08391369  1.17486889 ... 58.83333333 52.\n",
      "  71.        ]\n",
      " [ 6.          1.08391145  1.17486404 ... 58.83333333 52.\n",
      "  71.        ]\n",
      " [ 6.          1.08389088  1.17481944 ... 58.83333333 52.\n",
      "  71.        ]\n",
      " ...\n",
      " [ 4.          1.28956366  1.66297444 ... 56.5        51.\n",
      "  62.        ]\n",
      " [ 7.          1.03389137  1.06893137 ... 56.28571429 40.\n",
      "  72.        ]\n",
      " [ 5.          1.17001237  1.36892895 ... 59.4        51.\n",
      "  70.        ]]\n",
      "[[ 6.          1.10593992  1.22310311 ... 61.16666667 52.\n",
      "  69.        ]\n",
      " [ 6.          1.10593992  1.22310311 ... 61.         52.\n",
      "  69.        ]\n",
      " [ 6.          1.10593992  1.22310311 ... 61.         52.\n",
      "  69.        ]\n",
      " ...\n",
      " [ 5.          1.15580915  1.33589479 ... 58.4        52.\n",
      "  64.        ]\n",
      " [ 4.          1.28956366  1.66297444 ... 57.25       51.\n",
      "  63.        ]\n",
      " [ 4.          1.28956366  1.66297444 ... 57.25       51.\n",
      "  63.        ]]\n",
      "3860\n",
      "['bot' 'clothes' 'plastic' 'steel']\n",
      "[[ 5.          1.47538311  2.17675533 ... 59.8        52.\n",
      "  69.        ]\n",
      " [ 5.          1.47539672  2.17679547 ... 59.6        52.\n",
      "  69.        ]\n",
      " [ 5.          1.47541623  2.17685306 ... 59.6        52.\n",
      "  69.        ]\n",
      " ...\n",
      " [ 4.          1.27498529  1.62558748 ... 61.75       52.\n",
      "  74.        ]\n",
      " [ 8.          1.31157691  1.72023398 ... 58.5        52.\n",
      "  73.        ]\n",
      " [ 8.          1.31155986  1.72018926 ... 58.75       52.\n",
      "  71.        ]]\n",
      "[[ 4.          1.33139032  1.77260019 ... 59.         52.\n",
      "  69.        ]\n",
      " [ 4.          1.33139032  1.77260019 ... 59.         52.\n",
      "  69.        ]\n",
      " [ 4.          1.33135468  1.7725053  ... 58.75       51.\n",
      "  69.        ]\n",
      " ...\n",
      " [ 5.          1.16460441  1.35630344 ... 59.4        52.\n",
      "  72.        ]\n",
      " [ 5.          1.16153678  1.3491677  ... 59.8        52.\n",
      "  73.        ]\n",
      " [ 6.          1.06085435  1.12541195 ... 59.         52.\n",
      "  72.        ]]\n",
      "[[ 5.          1.20894859  1.46155669 ... 61.         52.\n",
      "  68.        ]\n",
      " [ 6.          1.11698684  1.24765959 ... 62.16666667 51.\n",
      "  68.        ]\n",
      " [ 6.          1.11700061  1.24769037 ... 62.16666667 52.\n",
      "  68.        ]\n",
      " ...\n",
      " [ 6.          1.07507154  1.15577882 ... 60.16666667 53.\n",
      "  70.        ]\n",
      " [ 6.          1.07508056  1.15579821 ... 59.83333333 52.\n",
      "  71.        ]\n",
      " [ 5.          1.17715358  1.38569055 ... 60.4        53.\n",
      "  71.        ]]\n",
      "[[ 3.          1.49711033  2.24133933 ... 61.         54.\n",
      "  67.        ]\n",
      " [ 3.          1.49714691  2.24144888 ... 61.         54.\n",
      "  67.        ]\n",
      " [ 3.          1.49714691  2.24144888 ... 61.         54.\n",
      "  67.        ]\n",
      " ...\n",
      " [ 3.          1.46181025  2.1368892  ... 58.33333333 54.\n",
      "  63.        ]\n",
      " [ 3.          1.46181025  2.1368892  ... 58.33333333 54.\n",
      "  63.        ]\n",
      " [ 3.          1.46181025  2.1368892  ... 58.33333333 54.\n",
      "  63.        ]]\n",
      "3811\n",
      "['bot' 'clothes' 'plastic' 'steel']\n",
      "[[ 7.          1.00789032  1.0158429  ... 53.28571429 46.\n",
      "  61.        ]\n",
      " [ 6.          1.01520895  1.03064921 ... 53.66666667 46.\n",
      "  61.        ]\n",
      " [ 6.          1.01520895  1.03064921 ... 53.         45.\n",
      "  61.        ]\n",
      " ...\n",
      " [ 6.          1.31844827  1.73830584 ... 53.5        45.\n",
      "  61.        ]\n",
      " [ 7.          1.44376998  2.08447174 ... 52.57142857 45.\n",
      "  60.        ]\n",
      " [ 6.          1.31432461  1.72744919 ... 53.         45.\n",
      "  61.        ]]\n",
      "[[ 6.          1.69099744  2.85947236 ... 55.5        47.\n",
      "  62.        ]\n",
      " [ 5.          1.72570227  2.97804834 ... 56.4        48.\n",
      "  61.        ]\n",
      " [ 6.          1.69099379  2.85945999 ... 55.16666667 47.\n",
      "  61.        ]\n",
      " ...\n",
      " [ 8.          1.50295565  2.25887567 ... 55.625      48.\n",
      "  63.        ]\n",
      " [ 6.          1.46437968  2.14440786 ... 57.16666667 47.\n",
      "  63.        ]\n",
      " [ 5.          0.98046379  0.96130925 ... 56.2        47.\n",
      "  62.        ]]\n",
      "[[ 4.          1.05132379  1.10528171 ... 53.75       47.\n",
      "  58.        ]\n",
      " [ 4.          1.05134246  1.10532098 ... 53.75       47.\n",
      "  58.        ]\n",
      " [ 5.          0.97496271  0.95055229 ... 53.8        48.\n",
      "  59.        ]\n",
      " ...\n",
      " [ 7.          1.4674745   2.15348141 ... 55.57142857 48.\n",
      "  60.        ]\n",
      " [ 8.          1.46703511  2.15219201 ... 54.5        47.\n",
      "  61.        ]\n",
      " [ 6.          1.42267714  2.02401025 ... 55.66666667 48.\n",
      "  60.        ]]\n",
      "[[ 6.          0.95399898  0.91011406 ... 54.         45.\n",
      "  60.        ]\n",
      " [ 8.          0.88206863  0.77804507 ... 53.125      45.\n",
      "  61.        ]\n",
      " [ 8.          0.88206956  0.7780467  ... 52.375      45.\n",
      "  60.        ]\n",
      " ...\n",
      " [ 5.          1.79022674  3.20491178 ... 49.4        44.\n",
      "  53.        ]\n",
      " [ 5.          1.82977269  3.34806809 ... 49.6        45.\n",
      "  54.        ]\n",
      " [ 5.          1.44841365  2.0979021  ... 50.8        46.\n",
      "  60.        ]]\n",
      "3453\n",
      "3860\n",
      "3811\n",
      "3453\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "tform=transforms.Compose([\n",
    "                           transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "def fileFeedforGNN(name):\n",
    "\n",
    "  data = pd.read_table(name)\n",
    "\n",
    "  y = data.iloc[:,-3].values\n",
    "  \n",
    "  \n",
    "  print(np.unique(y))\n",
    "\n",
    "\n",
    "  graphList = []\n",
    "  \n",
    "\n",
    "\n",
    "    \n",
    "  #num_objects\tr_std\tr_var\tr_mean\tr_min\tr_max\tsnr_std\tsnr_var\tsnr_mean\tsnr_min\tsnr_max\tnoise_std\tnoise_var\tnoise_mean\tnoise_min\tnoise_max\tobj\tenvironment\t\n",
    "  X_array = data.iloc[:, 0:16].values\n",
    "  \n",
    "\n",
    "  addList_bot, addList_clothes, addList_plastics, addList_steel  = [],[],[],[]\n",
    "    \n",
    "  for i in range(len(X_array)):\n",
    "    intarray = np.concatenate((X_array[i],X_array[i]),axis =0)\n",
    "    if(y[i] =='bot'):\n",
    "      addList_bot.append(intarray)\n",
    "    elif (y[i] == 'clothes'):\n",
    "      addList_clothes.append(intarray)\n",
    "    elif (y[i] == 'plastic'):\n",
    "      addList_plastics.append(intarray)\n",
    "    elif (y[i] == 'steel'):\n",
    "      addList_steel.append(intarray)\n",
    "  \n",
    "\n",
    "  for i in range(len(addList_bot) - 31):\n",
    "        \n",
    "        img = np.array(addList_bot[i:i+32])\n",
    "        \n",
    "        if(i<1):\n",
    "            print(img)\n",
    "        \n",
    "        graphList.append((tform(img),0))\n",
    "\n",
    "  for i in range(len(addList_clothes) - 31):\n",
    "    \n",
    "        img = np.array(addList_clothes[i:i+32])\n",
    "        \n",
    "        if(i<1):\n",
    "            print(img)\n",
    "        \n",
    "        graphList.append((tform(img),1))\n",
    "        \n",
    "  for i in range(len(addList_plastics) - 31):\n",
    "        img = np.array(addList_plastics[i:i+32])\n",
    "        \n",
    "        if(i<1):\n",
    "            print(img)\n",
    "            \n",
    "        graphList.append((tform(img),2))\n",
    "        \n",
    "  for i in range(len(addList_steel) - 31):\n",
    "    \n",
    "        img = np.array(addList_steel[i:i+32])\n",
    "        \n",
    "        if(i<1):\n",
    "            print(img)\n",
    "        graphList.append((tform(img),3))\n",
    "  \n",
    "  \n",
    "  \n",
    "  print(len(graphList))\n",
    "    \n",
    "    \n",
    " \n",
    "  return graphList\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################## data loading for 3.5 inch#####################\n",
    "\n",
    "graphList_lablight_3_5 = fileFeedforGNN('lablight_3.5_.txt')\n",
    "graphList_night_3_5 = fileFeedforGNN('night_3.5_.txt')\n",
    "graphList_sunny_3_5 = fileFeedforGNN('sunny_3.5_.txt')\n",
    "\n",
    "\n",
    "lablight_train_len = int(len(graphList_lablight_3_5)*0.7)\n",
    "night_train_len = int(len(graphList_night_3_5)*0.7)\n",
    "sunny_tarin_len = int(len(graphList_sunny_3_5)*0.7)\n",
    "\n",
    "\n",
    "batch_size=64\n",
    "test_batch_size=64\n",
    "\n",
    "random.shuffle(graphList_lablight_3_5)\n",
    "random.shuffle(graphList_night_3_5)\n",
    "random.shuffle(graphList_sunny_3_5)\n",
    "\n",
    "train_loader_lablight_3_5 = torch.utils.data.DataLoader(graphList_lablight_3_5[0:lablight_train_len],batch_size)  \n",
    "test_loader_lablight_3_5 = torch.utils.data.DataLoader(graphList_lablight_3_5[lablight_train_len:],test_batch_size) \n",
    "\n",
    "train_loader_night_3_5 = torch.utils.data.DataLoader(graphList_night_3_5[0:night_train_len],batch_size)  \n",
    "test_loader_night_3_5 = torch.utils.data.DataLoader(graphList_night_3_5[night_train_len:],test_batch_size) \n",
    "\n",
    "train_loader_sunny_3_5 = torch.utils.data.DataLoader(graphList_sunny_3_5[0:sunny_tarin_len],batch_size)  \n",
    "test_loader_sunny_3_5 = torch.utils.data.DataLoader(graphList_sunny_3_5[sunny_tarin_len:],test_batch_size) \n",
    "\n",
    "print(len(graphList_lablight_3_5))\n",
    "print(len(graphList_night_3_5))\n",
    "print(len(graphList_sunny_3_5))\n",
    "\n",
    "\n",
    "\n",
    "############################## data loading for 7 inch#####################\n",
    "\n",
    "graphList_lablight_7= fileFeedforGNN('lablight_7_.txt')\n",
    "graphList_night_7 = fileFeedforGNN('night_7_.txt')\n",
    "graphList_sunny_7 = fileFeedforGNN('sunny_7_.txt')\n",
    "\n",
    "\n",
    "lablight_train_len = int(len(graphList_lablight_7)*0.7)\n",
    "night_train_len = int(len(graphList_night_7)*0.7)\n",
    "sunny_tarin_len = int(len(graphList_sunny_7)*0.7)\n",
    "\n",
    "\n",
    "batch_size=64\n",
    "test_batch_size=64\n",
    "\n",
    "random.shuffle(graphList_lablight_7)\n",
    "random.shuffle(graphList_night_7)\n",
    "random.shuffle(graphList_sunny_7)\n",
    "\n",
    "train_loader_lablight_7 = torch.utils.data.DataLoader(graphList_lablight_7[0:lablight_train_len],batch_size)  \n",
    "test_loader_lablight_7 = torch.utils.data.DataLoader(graphList_lablight_7[lablight_train_len:],test_batch_size) \n",
    "\n",
    "train_loader_night_7 = torch.utils.data.DataLoader(graphList_night_7[0:night_train_len],batch_size)  \n",
    "test_loader_night_7 = torch.utils.data.DataLoader(graphList_night_7[night_train_len:],test_batch_size) \n",
    "\n",
    "train_loader_sunny_7= torch.utils.data.DataLoader(graphList_sunny_7[0:sunny_tarin_len],batch_size)  \n",
    "test_loader_sunny_7= torch.utils.data.DataLoader(graphList_sunny_7[sunny_tarin_len:],test_batch_size) \n",
    "\n",
    "print(len(graphList_lablight_7))\n",
    "print(len(graphList_night_7))\n",
    "print(len(graphList_sunny_7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.autograd import Function\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "    \n",
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchvision import datasets\n",
    "\n",
    "class ReverseLayerF(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "\n",
    "        return output, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "\n",
    "class_labels = 4\n",
    "classes = ('bot', 'clothes', 'plastic', 'steel')\n",
    "\n",
    "\n",
    "conv_val = 26\n",
    "out_channel = 16\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.feature = nn.Sequential()\n",
    "        self.feature.add_module('f_conv1', nn.Conv2d(1, 4, 3))\n",
    "        self.feature.add_module('f_relu1', nn.ReLU(True))\n",
    "        self.feature.add_module('f_conv2', nn.Conv2d(4, 8, 3))\n",
    "        self.feature.add_module('f_relu2', nn.ReLU(True))\n",
    "        self.feature.add_module('f_conv3', nn.Conv2d(8, 16, 3))\n",
    "        self.feature.add_module('f_relu3', nn.ReLU(True))\n",
    "      \n",
    "        \n",
    "        self.class_classifier = nn.Sequential()\n",
    "        self.class_classifier.add_module('c_fc1', nn.Linear(out_channel* conv_val *conv_val, 120))\n",
    "        self.class_classifier.add_module('c_relu1', nn.ReLU(True))\n",
    "        self.class_classifier.add_module('c_fc2', nn.Linear(120, 84))\n",
    "        self.class_classifier.add_module('c_relu2', nn.ReLU(True))\n",
    "        self.class_classifier.add_module('c_fc3', nn.Linear(84,4))\n",
    "        \n",
    "        self.domain_classifier = nn.Sequential()\n",
    "        self.domain_classifier.add_module('d_fc1', nn.Linear(out_channel* conv_val *conv_val, 120))\n",
    "        self.domain_classifier.add_module('d_relu1', nn.ReLU(True))\n",
    "        self.domain_classifier.add_module('d_fc2', nn.Linear(120, 2))\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, input_data, alpha):\n",
    "        \n",
    "        \n",
    "       \n",
    "        feature = self.feature(input_data)\n",
    "        feature = feature.view(-1, out_channel* conv_val *conv_val)\n",
    "        reverse_feature = ReverseLayerF.apply(feature, alpha)\n",
    "        class_output = self.class_classifier(feature)\n",
    "        domain_output = self.domain_classifier(reverse_feature)\n",
    "\n",
    "        return class_output, domain_output\n",
    "      \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test(dataset_name):\n",
    "    #assert dataset_name in ['MNIST', 'mnist_m']\n",
    "\n",
    "    model_root = ''\n",
    "    image_root = os.path.join('dataset', dataset_name)\n",
    "\n",
    "    cuda = True\n",
    "    cudnn.benchmark = True\n",
    "    batch_size =  64\n",
    "    image_size = 28\n",
    "    alpha = 0\n",
    "\n",
    "    \"\"\"load data\"\"\"\n",
    "\n",
    "    img_transform_source = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "    ])\n",
    "\n",
    "    img_transform_target = transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    if dataset_name == 'mnist_m':\n",
    "        test_list = os.path.join(image_root, 'mnist_m_test_labels.txt')\n",
    "\n",
    "        dataset = GetLoader(\n",
    "            data_root=os.path.join(image_root, 'mnist_m_test'),\n",
    "            data_list=test_list,\n",
    "            transform=img_transform_target\n",
    "        )\n",
    "    else:\n",
    "        dataset = datasets.MNIST(\n",
    "            root='dataset',\n",
    "            train=False,\n",
    "            transform=img_transform_source,\n",
    "        )\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=8\n",
    "    )\n",
    "\n",
    "    \"\"\" test \"\"\"\n",
    "\n",
    "    my_net = torch.load(os.path.join(\n",
    "        model_root, 'mnist_mnistm_model_epoch_current.pth'\n",
    "    ))\n",
    "    my_net = my_net.eval()\n",
    "\n",
    "    if cuda:\n",
    "        my_net = my_net.cuda()\n",
    "\n",
    "    len_dataloader = len(dataloader)\n",
    "    data_target_iter = iter(dataloader)\n",
    "\n",
    "    i = 0\n",
    "    n_total = 0\n",
    "    n_correct = 0\n",
    "\n",
    "    while i < len_dataloader:\n",
    "\n",
    "        # test model using target data\n",
    "        data_target = next(data_target_iter)\n",
    "        t_img, t_label = data_target\n",
    "\n",
    "        batch_size = len(t_label)\n",
    "\n",
    "        if cuda:\n",
    "            t_img = t_img.cuda()\n",
    "            t_label = t_label.cuda()\n",
    "\n",
    "        class_output, _ = my_net(input_data=t_img, alpha=alpha)\n",
    "        pred = class_output.data.max(1, keepdim=True)[1]\n",
    "        n_correct += pred.eq(t_label.data.view_as(pred)).cpu().sum()\n",
    "        n_total += batch_size\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    accu = n_correct.data.numpy() * 1.0 / n_total\n",
    "\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/MNIST\n",
      "dataset/mnist_m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1cf1fe945bb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mmanual_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/random.py\u001b[0m in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_in_bad_fork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;31m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mcb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mdefault_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_generators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import sys\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "\n",
    "source_dataset_name = 'MNIST'\n",
    "target_dataset_name = 'mnist_m'\n",
    "source_image_root = os.path.join('dataset', source_dataset_name)\n",
    "print(source_image_root)\n",
    "target_image_root = os.path.join('dataset', target_dataset_name)\n",
    "print(target_image_root)\n",
    "model_root = 'models'\n",
    "cuda = True\n",
    "cudnn.benchmark = True\n",
    "lr = 1e-3\n",
    "batch_size = 128\n",
    "image_size = 28\n",
    "n_epoch = 5\n",
    "\n",
    "manual_seed = random.randint(1, 10000)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "# load data\n",
    "\n",
    "img_transform_source = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "])\n",
    "\n",
    "img_transform_target = transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset_source = datasets.MNIST(\n",
    "    root='dataset',\n",
    "    train=True,\n",
    "    transform=img_transform_source,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "dataloader_source = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_source,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8)\n",
    "\n",
    "# print(\"dataloader_source.shape\")\n",
    "# print(dataloader_source.shape())\n",
    "\n",
    "train_list = os.path.join(target_image_root, 'mnist_m_train_labels.txt')\n",
    "\n",
    "dataset_target = GetLoader(\n",
    "    data_root=os.path.join(target_image_root, 'mnist_m_train'),\n",
    "    data_list=train_list,\n",
    "    transform=img_transform_target\n",
    ")\n",
    "\n",
    "dataloader_target = torch.utils.data.DataLoader(\n",
    "    dataset=dataset_target,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8)\n",
    "\n",
    "# load model\n",
    "\n",
    "# print(\"dataloader_target.shape\")\n",
    "# print(dataloader_target.shape())\n",
    "\n",
    "my_net = CNNModel()\n",
    "\n",
    "# setup optimizer\n",
    "\n",
    "optimizer = optim.Adam(my_net.parameters(), lr=lr)\n",
    "\n",
    "loss_class = torch.nn.NLLLoss()\n",
    "loss_domain = torch.nn.NLLLoss()\n",
    "\n",
    "if cuda:\n",
    "    my_net = my_net.cuda()\n",
    "    loss_class = loss_class.cuda()\n",
    "    loss_domain = loss_domain.cuda()\n",
    "\n",
    "for p in my_net.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "# training\n",
    "best_accu_t = 0.0\n",
    "\n",
    "accList = []\n",
    "errList = []\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "\n",
    "    len_dataloader = min(len(dataloader_source), len(dataloader_target))\n",
    "    data_source_iter = iter(dataloader_source)\n",
    "    data_target_iter = iter(dataloader_target)\n",
    "\n",
    "    for i in range(len_dataloader):\n",
    "\n",
    "        p = float(i + epoch * len_dataloader) / n_epoch / len_dataloader\n",
    "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "\n",
    "        # training model using source data\n",
    "        data_source = next(data_source_iter)\n",
    "        s_img, s_label = data_source\n",
    "        \n",
    "        # print('\\n')\n",
    "        # print(s_img.shape)\n",
    "        # print(s_label)\n",
    "\n",
    "        my_net.zero_grad()\n",
    "        batch_size = len(s_label)\n",
    "\n",
    "        domain_label = torch.zeros(batch_size).long()\n",
    "\n",
    "        if cuda:\n",
    "            s_img = s_img.cuda()\n",
    "            s_label = s_label.cuda()\n",
    "            domain_label = domain_label.cuda()\n",
    "\n",
    "\n",
    "        class_output, domain_output = my_net(input_data=s_img, alpha=alpha)\n",
    "        err_s_label = loss_class(class_output, s_label)\n",
    "        err_s_domain = loss_domain(domain_output, domain_label)\n",
    "\n",
    "        # training model using target data\n",
    "        data_target = next(data_target_iter)\n",
    "        t_img, _ = data_target\n",
    "        \n",
    "        \n",
    "        # print('\\n I am in targert')\n",
    "        # print(t_img.shape)\n",
    "        # print(_)\n",
    "\n",
    "        batch_size = len(t_img)\n",
    "\n",
    "        domain_label = torch.ones(batch_size).long()\n",
    "\n",
    "        if cuda:\n",
    "            t_img = t_img.cuda()\n",
    "            domain_label = domain_label.cuda()\n",
    "\n",
    "        _, domain_output = my_net(input_data=t_img, alpha=alpha)\n",
    "        err_t_domain = loss_domain(domain_output, domain_label)\n",
    "        err = err_t_domain + err_s_domain + err_s_label\n",
    "        err.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        errList.append(err)\n",
    "\n",
    "        sys.stdout.write('\\r epoch: %d, [iter: %d / all %d], err_s_label: %f, err_s_domain: %f, err_t_domain: %f' \\\n",
    "              % (epoch, i + 1, len_dataloader, err_s_label.data.cpu().numpy(),\n",
    "                 err_s_domain.data.cpu().numpy(), err_t_domain.data.cpu().item()))\n",
    "        sys.stdout.flush()\n",
    "        torch.save(my_net, 'mnist_mnistm_model_epoch_current.pth'.format(model_root))\n",
    "\n",
    "    print('\\n')\n",
    "    accu_s = test(source_dataset_name)\n",
    "    print('Accuracy of the %s dataset: %f' % ('mnist', accu_s))\n",
    "    accu_t = test(target_dataset_name)\n",
    "    print('Accuracy of the %s dataset: %f\\n' % ('mnist_m', accu_t))\n",
    "    accList.append([accu_s,accu_t])\n",
    "    if accu_t > best_accu_t:\n",
    "        best_accu_s = accu_s\n",
    "        best_accu_t = accu_t\n",
    "        torch.save(my_net, 'mnist_mnistm_model_epoch_best.pth'.format(model_root))\n",
    "\n",
    "print('============ Summary ============= \\n')\n",
    "print('Accuracy of the %s dataset: %f' % ('mnist', best_accu_s))\n",
    "print('Accuracy of the %s dataset: %f' % ('mnist_m', best_accu_t))\n",
    "print('Corresponding model was save in ' + model_root + 'mnist_mnistm_model_epoch_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b4738f1cc6c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#print(y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accList' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "x = [i for i in range(150)]\n",
    "\n",
    "\n",
    "sns.set(rc={'figure.figsize':(16,16) },font_scale=1.2)\n",
    "fig, ax0 = plt.subplots(1, 1)\n",
    "\n",
    "y1 = accList\n",
    "\n",
    "    #print(y)\n",
    "var = 7\n",
    "\n",
    "# plotting strip plot with seaborn\n",
    "sns.lineplot(x, y1,ax=ax0,linewidth = var)\n",
    "\n",
    "\n",
    "y2 = lossList\n",
    "#print(y)\n",
    "\n",
    "sns.lineplot(x, y2, ax = ax0,linewidth = var)\n",
    "\n",
    "# giving labels to x-axis and y-axis\n",
    "ax0.set(xlabel ='Epochs', ylabel ='Loss or Testing accuracy')\n",
    "\n",
    "ax0.set_xlabel(ax0.get_xlabel(), fontdict={'weight': 'bold'}, fontsize = 20)\n",
    "ax0.set_ylabel(ax0.get_ylabel(), fontdict={'weight': 'bold'},fontsize = 20)\n",
    "ax0.legend(['Testing Accuracy', 'Train loss'],fontsize = 20,loc='upper center',bbox_to_anchor=(0.5, 1.09),\n",
    "ncol=2)\n",
    "\n",
    "plt.savefig('lablight'+'.PNG', bbox_inches = \"tight\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "     |████████████████████████████████| 292 kB 14.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.1.5)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.19.5)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.3.4)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.5.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (3.0.6)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "!pip3 install seaborn"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
